{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # import re for regular expressions \n",
    "import string # import string for string operations and manipulation\n",
    "import nltk # import nltk for natural language processing \n",
    "from nltk.corpus import stopwords # import stopwords from nltk corpus \n",
    "from nltk.stem import WordNetLemmatizer # import WordNetLemmatizer from nltk stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zeal.v/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zeal.v/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/zeal.v/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/zeal.v/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked\n",
      "0                           Wow... Loved this place.      1\n",
      "1                                 Crust is not good.      0\n",
      "2          Not tasty and the texture was just nasty.      0\n",
      "3  Stopped by during the late May bank holiday of...      1\n",
      "4  The selection on the menu was great and so wer...      1\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the file path from the .env file\n",
    "file_path = os.getenv('FILE_PATH')\n",
    "\n",
    "# Load the .tsv file\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1000 non-null   object\n",
      " 1   Liked   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  \\\n",
      "0                           Wow... Loved this place.   \n",
      "1                                 Crust is not good.   \n",
      "2          Not tasty and the texture was just nasty.   \n",
      "3  Stopped by during the late May bank holiday of...   \n",
      "4  The selection on the menu was great and so wer...   \n",
      "\n",
      "                                      Cleaned_Review  \n",
      "0                                    wow loved place  \n",
      "1                                         crust good  \n",
      "2                                tasty texture nasty  \n",
      "3  stopped late may bank holiday rick steve recom...  \n",
      "4                         selection menu great price  \n"
     ]
    }
   ],
   "source": [
    "# Define a preprocessing function\n",
    "def preprocess_text(doc):\n",
    "    # Convert to lowercase\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [w.translate(str.maketrans('', '', string.punctuation)) for w in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  \\\n",
      "0                           Wow... Loved this place.   \n",
      "1                                 Crust is not good.   \n",
      "2          Not tasty and the texture was just nasty.   \n",
      "3  Stopped by during the late May bank holiday of...   \n",
      "4  The selection on the menu was great and so wer...   \n",
      "\n",
      "                                      text_processed  \n",
      "0                                    wow loved place  \n",
      "1                                         crust good  \n",
      "2                                tasty texture nasty  \n",
      "3  stopped late may bank holiday rick steve recom...  \n",
      "4                         selection menu great price  \n"
     ]
    }
   ],
   "source": [
    "# Apply the preprocessing function to the 'Review' column\n",
    "df['text_processed'] = df['Review'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(df[['Review', 'text_processed']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
